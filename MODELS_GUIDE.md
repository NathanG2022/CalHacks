# PromptBreakr - Available AI Models Guide

This guide provides comprehensive information about all 20 open-source AI models integrated into PromptBreakr from Hugging Face.

## üìä Models Overview

**Total Models:** 20
**Categories:** 6
- Instruction-tuned (5 models)
- Chat-optimized (3 models)
- Code-specialized (2 models)
- General Purpose (3 models)
- Lightweight/Fast (3 models)
- Multilingual (2 models)

---

## üéØ Instruction-Tuned Models
*Best for following complex instructions and structured tasks*

### 1. Qwen 2.5 7B Instruct
- **Model ID:** `Qwen/Qwen2.5-7B-Instruct`
- **Size:** 7 billion parameters
- **Provider:** Qwen (Alibaba)
- **Icon:** ü§ñ
- **Best For:** High-performance instruction-following, reasoning, code generation
- **Description:** Excellent all-around model with strong instruction-following capabilities
- **Use Cases:** General tasks, reasoning, structured outputs

### 2. Qwen 2.5 14B Instruct
- **Model ID:** `Qwen/Qwen2.5-14B-Instruct`
- **Size:** 14 billion parameters
- **Provider:** Qwen (Alibaba)
- **Icon:** üöÄ
- **Best For:** Advanced reasoning, complex tasks, multilingual support
- **Description:** Larger version with enhanced capabilities and better reasoning
- **Use Cases:** Complex reasoning, multilingual tasks, advanced problem-solving

### 3. Mistral 7B Instruct v0.3
- **Model ID:** `mistralai/Mistral-7B-Instruct-v0.3`
- **Size:** 7 billion parameters
- **Provider:** Mistral AI
- **Icon:** ‚ö°
- **Best For:** Fast inference, instruction-following, reasoning
- **Description:** Powerful and efficient instruction model with excellent performance
- **Use Cases:** Fast responses, instruction tasks, balanced performance

### 4. Meta Llama 3.1 8B Instruct
- **Model ID:** `meta-llama/Meta-Llama-3.1-8B-Instruct`
- **Size:** 8 billion parameters
- **Provider:** Meta
- **Icon:** ü¶ô
- **Best For:** Advanced reasoning, multilingual support, instruction-following
- **Description:** Meta's latest open-source model with state-of-the-art capabilities
- **Use Cases:** Complex reasoning, multilingual tasks, instruction-following

### 5. Gemma 2 9B IT
- **Model ID:** `google/gemma-2-9b-it`
- **Size:** 9 billion parameters
- **Provider:** Google
- **Icon:** üíé
- **Best For:** Safety-focused tasks, reasoning, instruction-following
- **Description:** Google's instruction-tuned model with enhanced safety features
- **Use Cases:** Safe content generation, instruction-following, reasoning

---

## üí¨ Chat-Optimized Models
*Specialized for natural conversations and dialogue*

### 6. DialoGPT Medium
- **Model ID:** `microsoft/DialoGPT-medium`
- **Size:** Medium (345M parameters)
- **Provider:** Microsoft
- **Icon:** üí¨
- **Best For:** Natural dialogue, conversational AI, chat applications
- **Description:** Trained on Reddit conversations for engaging dialogue
- **Use Cases:** Chatbots, conversational interfaces, dialogue systems

### 7. DialoGPT Large
- **Model ID:** `microsoft/DialoGPT-large`
- **Size:** Large (774M parameters)
- **Provider:** Microsoft
- **Icon:** üó®Ô∏è
- **Best For:** Enhanced conversations, more context-aware dialogue
- **Description:** Larger version with better context understanding
- **Use Cases:** Advanced chatbots, multi-turn conversations, context-aware dialogue

### 8. BlenderBot 400M
- **Model ID:** `facebook/blenderbot-400M-distill`
- **Size:** 400 million parameters
- **Provider:** Meta (Facebook)
- **Icon:** ü§ù
- **Best For:** Engaging conversations, empathetic responses, knowledge grounding
- **Description:** Distilled version optimized for conversational engagement
- **Use Cases:** Empathetic chatbots, knowledge-grounded conversations, engaging dialogue

---

## üíª Code-Specialized Models
*Optimized for code generation and understanding*

### 9. StarCoder2 7B
- **Model ID:** `bigcode/starcoder2-7b`
- **Size:** 7 billion parameters
- **Provider:** BigCode
- **Icon:** üíª
- **Best For:** Code generation, code completion, multi-language programming
- **Description:** State-of-the-art code model supporting 600+ languages
- **Use Cases:** Code generation, debugging, code completion, documentation

### 10. CodeGen 350M Multi
- **Model ID:** `Salesforce/codegen-350M-multi`
- **Size:** 350 million parameters
- **Provider:** Salesforce
- **Icon:** ‚å®Ô∏è
- **Best For:** Fast code generation, multi-language support
- **Description:** Lightweight code model with multi-language capabilities
- **Use Cases:** Quick code snippets, multi-language coding, fast inference

---

## üß† General Purpose Models
*Versatile models for various text generation tasks*

### 11. GPT-Neo 2.7B
- **Model ID:** `EleutherAI/gpt-neo-2.7B`
- **Size:** 2.7 billion parameters
- **Provider:** EleutherAI
- **Icon:** üß†
- **Best For:** General text generation, creative writing, open-source alternative
- **Description:** Open-source GPT-style model with strong general capabilities
- **Use Cases:** Creative writing, general text generation, experiments

### 12. GPT-J 6B
- **Model ID:** `EleutherAI/gpt-j-6b`
- **Size:** 6 billion parameters
- **Provider:** EleutherAI
- **Icon:** üéØ
- **Best For:** Powerful text generation, reasoning, creative writing
- **Description:** Larger and more capable than GPT-Neo
- **Use Cases:** Complex text generation, reasoning tasks, creative content

### 13. Falcon 7B Instruct
- **Model ID:** `tiiuae/falcon-7b-instruct`
- **Size:** 7 billion parameters
- **Provider:** Technology Innovation Institute (TII)
- **Icon:** ü¶Ö
- **Best For:** High-performance instruction-following, multilingual support
- **Description:** Powerful open-source model with excellent performance
- **Use Cases:** Instruction-following, multilingual tasks, general AI applications

---

## ‚ö° Lightweight/Fast Models
*Optimized for speed and efficiency*

### 14. GPT-2
- **Model ID:** `gpt2`
- **Size:** 124 million parameters
- **Provider:** OpenAI
- **Icon:** ‚ö°
- **Best For:** Fast inference, baseline comparisons, low-resource environments
- **Description:** Classic model, good for quick responses and baselines
- **Use Cases:** Fast prototyping, baseline testing, low-latency applications

### 15. GPT-2 Medium
- **Model ID:** `gpt2-medium`
- **Size:** 355 million parameters
- **Provider:** OpenAI
- **Icon:** üèÉ
- **Best For:** Balanced speed and quality
- **Description:** Larger than base GPT-2 with better quality
- **Use Cases:** Balanced applications, moderate complexity tasks

### 16. DistilGPT-2
- **Model ID:** `distilgpt2`
- **Size:** 82 million parameters
- **Provider:** HuggingFace
- **Icon:** ‚ö°
- **Best For:** Very fast inference, resource-constrained environments
- **Description:** Distilled version of GPT-2, 2x faster with minimal quality loss
- **Use Cases:** Real-time applications, mobile/edge deployment, fast testing

---

## üåç Multilingual Models
*Supporting multiple languages for global applications*

### 17. BLOOM 560M
- **Model ID:** `bigscience/bloom-560m`
- **Size:** 560 million parameters
- **Provider:** BigScience
- **Icon:** üåç
- **Best For:** 46 languages support, multilingual text generation
- **Description:** Massively multilingual model supporting diverse languages
- **Supported Languages:** English, French, Spanish, Arabic, Chinese, Hindi, and 40+ more
- **Use Cases:** Multilingual chatbots, translation assistance, global applications

### 18. XGLM 564M
- **Model ID:** `facebook/xglm-564M`
- **Size:** 564 million parameters
- **Provider:** Meta (Facebook)
- **Icon:** üåê
- **Best For:** Cross-lingual generation, multilingual understanding
- **Description:** Cross-lingual model with strong multilingual capabilities
- **Use Cases:** Cross-lingual transfer, multilingual applications, language understanding

---

## üéØ Choosing the Right Model

### For Jailbreaking/Red-Teaming:
1. **Best Overall:** Qwen 2.5 14B Instruct or Meta Llama 3.1 8B
2. **Fastest:** Mistral 7B Instruct v0.3 or DistilGPT-2
3. **Most Creative:** GPT-J 6B or GPT-Neo 2.7B
4. **Code-focused:** StarCoder2 7B
5. **Conversation:** DialoGPT Large or BlenderBot 400M

### By Use Case:
- **Complex Reasoning:** Qwen 2.5 14B, Meta Llama 3.1 8B
- **Fast Responses:** Mistral 7B, DistilGPT-2, GPT-2
- **Code Generation:** StarCoder2 7B, CodeGen 350M
- **Natural Dialogue:** DialoGPT Large, BlenderBot 400M
- **Multilingual:** BLOOM 560M, XGLM 564M
- **Safety Testing:** Gemma 2 9B IT (safety-focused)

### By Resource Constraints:
- **High-end (lots of memory):** Qwen 2.5 14B, Meta Llama 3.1 8B, GPT-J 6B
- **Medium:** Qwen 2.5 7B, Mistral 7B, Falcon 7B, StarCoder2 7B
- **Low (fast/efficient):** GPT-2, DistilGPT-2, CodeGen 350M, BLOOM 560M

---

## üîß Technical Details

### Model Configuration
All models are configured with:
- **Temperature:** 0.6-0.8 (adjustable via UI)
- **Top-p:** 0.9-0.95
- **Max Length:** 256-512 tokens (varies by model)

### API Integration
All models are integrated via:
- **HuggingFace Inference API** for real-time inference
- **Fallback responses** when API limits are reached
- **Server-side caching** for improved performance

### Features in Chat Interface:
- ‚úÖ Model search functionality
- ‚úÖ Category filtering (Instruction, Chat, Code, etc.)
- ‚úÖ Model metadata display (size, provider)
- ‚úÖ Real-time model switching
- ‚úÖ Compatible with all jailbreaking methods

---

## üìù Notes

### Model Access:
- Most models are publicly available on Hugging Face
- Some models (e.g., Meta Llama) may require accepting license agreements
- Ensure your `HUGGINGFACE_API_KEY` environment variable is set

### Performance:
- Larger models (14B+) provide better quality but slower responses
- Smaller models (<1B) are faster but may have lower quality
- Choose based on your latency/quality requirements

### Rate Limits:
- Free tier: Limited requests per hour
- Pro tier: Higher rate limits
- Consider implementing request queuing for production use

---

## üöÄ Getting Started

1. **Select a model** from the Chat interface sidebar
2. **Choose a jailbreaking method** (or use "None" for direct conversation)
3. **Start chatting** - the model will respond according to your settings
4. **Experiment** with different models to find what works best for your use case

For more information, visit the [HuggingFace Models Hub](https://huggingface.co/models)
